{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hn25wtQl4dPx","executionInfo":{"status":"ok","timestamp":1748277058376,"user_tz":-360,"elapsed":59653,"user":{"displayName":"Farhanaz Kamrun","userId":"08222259281601613108"}},"outputId":"9558da8f-0f8d-418a-f422-201a43088981"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","Cross-validated model performance summary:\n","\n","                 Model  accuracy  precision    recall        f1   roc_auc\n","0  K-Nearest Neighbors  0.781344   0.786896  0.780735  0.779952  0.837714\n","1        Decision Tree  0.781323   0.780680  0.789061  0.781459  0.781102\n","2        Random Forest  0.789384   0.797857  0.776816  0.784851  0.852976\n","3             AdaBoost  0.789384   0.795179  0.780898  0.785917  0.868551\n","4              XGBoost  0.749000   0.781718  0.699755  0.734653  0.832195\n","\n","Confusion Matrix Values for All Models:\n","\n","                 Model  TP  FP  TN  FN  Accuracy (%)  Precision (%)  \\\n","0  K-Nearest Neighbors  37   9  41  12         78.79          80.43   \n","1        Decision Tree  41  11  39   8         80.81          78.85   \n","2        Random Forest  36   9  41  13         77.78          80.00   \n","3             AdaBoost  36   9  41  13         77.78          80.00   \n","4              XGBoost  33   8  42  16         75.76          80.49   \n","\n","   Recall (%)  F1-Score (%)  \n","0       75.51         77.89  \n","1       83.67         81.19  \n","2       73.47         76.60  \n","3       73.47         76.60  \n","4       67.35         73.33  \n"]}],"source":["from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold, cross_validate, train_test_split\n","from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import (make_scorer, accuracy_score, precision_score,\n","                             recall_score, f1_score, roc_auc_score, confusion_matrix)\n","from scipy.stats import zscore\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","import xgboost as xgb\n","\n","\n","# 1. Mount Google Drive and load dataset\n","\n","drive.mount('/content/drive')\n","file_path = '/content/drive/MyDrive/Colab Notebooks/Balanced_Energy_Classification.csv'\n","df = pd.read_csv(file_path)\n","\n","# ───────────────────────────────────────────────────────────────\n","# 2. Remove any leaky or irrelevant columns (if applicable)\n","# ───────────────────────────────────────────────────────────────\n","target_col = 'EnergyClass'\n","X = df.drop(columns=[target_col])\n","y = df[target_col]\n","\n","# ───────────────────────────────────────────────────────────────\n","# 3. Identify column types\n","# ───────────────────────────────────────────────────────────────\n","num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n","cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n","\n","# ───────────────────────────────────────────────────────────────\n","# 4. Impute missing values\n","# ───────────────────────────────────────────────────────────────\n","num_imputer = SimpleImputer(strategy='median')\n","cat_imputer = SimpleImputer(strategy='most_frequent')\n","X[num_cols] = num_imputer.fit_transform(X[num_cols])\n","X[cat_cols] = cat_imputer.fit_transform(X[cat_cols])\n","\n","# ───────────────────────────────────────────────────────────────\n","# 5. Simple outlier capping (z-score > 3) on numeric columns\n","# ───────────────────────────────────────────────────────────────\n","z_scores = np.abs(zscore(X[num_cols]))\n","for i, col in enumerate(num_cols):\n","    col_z = z_scores[:, i]\n","    upper = X[col].mean() + 3 * X[col].std()\n","    lower = X[col].mean() - 3 * X[col].std()\n","    X.loc[col_z > 3,  col] = upper\n","    X.loc[col_z < -3, col] = lower\n","\n","# ───────────────────────────────────────────────────────────────\n","# 6. Basic filter-style feature selection (|corr| > 0.1)\n","# ───────────────────────────────────────────────────────────────\n","corr_with_target = X[num_cols].corrwith(y.astype(int))\n","selected_num_features = corr_with_target[abs(corr_with_target) > 0.1].index.tolist()\n","selected_cat_features = cat_cols\n","selected_features = selected_num_features + selected_cat_features\n","X = X[selected_features]\n","\n","num_cols = [c for c in selected_num_features if c in num_cols]\n","cat_cols = [c for c in selected_cat_features if c in cat_cols]\n","\n","# ───────────────────────────────────────────────────────────────\n","# 7. Preprocessing pipelines\n","# ───────────────────────────────────────────────────────────────\n","num_pipeline = Pipeline([('scaler', MinMaxScaler())])\n","cat_pipeline = Pipeline([('onehot', OneHotEncoder(handle_unknown='ignore'))])\n","preprocessor = ColumnTransformer([\n","    ('num', num_pipeline, num_cols),\n","    ('cat', cat_pipeline, cat_cols)\n","])\n","\n","# ───────────────────────────────────────────────────────────────\n","# 8. Candidate models (Logistic & SVM removed)\n","# ───────────────────────────────────────────────────────────────\n","models = {\n","    'K-Nearest Neighbors': KNeighborsClassifier(),\n","    'Decision Tree': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n","    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n","    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42),\n","    'XGBoost': xgb.XGBClassifier(eval_metric='logloss', random_state=42)\n","}\n","\n","# ───────────────────────────────────────────────────────────────\n","# 9. Scoring metrics\n","# ───────────────────────────────────────────────────────────────\n","scoring = {\n","    'accuracy':  make_scorer(accuracy_score),\n","    'precision': make_scorer(precision_score, zero_division=0),\n","    'recall':    make_scorer(recall_score,   zero_division=0),\n","    'f1':        make_scorer(f1_score,       zero_division=0),\n","    'roc_auc':   'roc_auc'\n","}\n","\n","# ───────────────────────────────────────────────────────────────\n","# 10. Cross-validation performance\n","# ───────────────────────────────────────────────────────────────\n","results = []\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","for name, clf in models.items():\n","    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n","                           ('classifier',   clf)])\n","    cv_results = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n","    results.append({\n","        'Model': name,\n","        **{metric: cv_results[f'test_{metric}'].mean() for metric in scoring}\n","    })\n","\n","results_df = pd.DataFrame(results)\n","print(\"\\nCross-validated model performance summary:\\n\")\n","print(results_df)\n","\n","# ───────────────────────────────────────────────────────────────\n","# 11. Confusion matrices on a hold-out test split\n","# ───────────────────────────────────────────────────────────────\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, stratify=y, test_size=0.2, random_state=42\n",")\n","\n","confusion_data = []\n","\n","print(\"\\nConfusion Matrix Values for All Models:\\n\")\n","\n","for name, clf in models.items():\n","    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n","                           ('classifier',   clf)])\n","    pipe.fit(X_train, y_train)\n","    y_pred = pipe.predict(X_test)\n","    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","    confusion_data.append({\n","        'Model':       name,\n","        'TP':          tp,\n","        'FP':          fp,\n","        'TN':          tn,\n","        'FN':          fn,\n","        'Accuracy (%)':  round(accuracy_score (y_test, y_pred) * 100, 2),\n","        'Precision (%)': round(precision_score(y_test, y_pred, zero_division=0) * 100, 2),\n","        'Recall (%)':    round(recall_score   (y_test, y_pred, zero_division=0) * 100, 2),\n","        'F1-Score (%)':  round(f1_score       (y_test, y_pred, zero_division=0) * 100, 2)\n","    })\n","\n","confusion_df = pd.DataFrame(confusion_data)\n","print(confusion_df)\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOySb49SAwsowtNWdabTL0s"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}